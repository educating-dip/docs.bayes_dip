<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>bayes_dip.inference.sample_based_predictive_posterior module &mdash; Bayes-DIP  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="bayes_dip.inference.utils module" href="bayes_dip.inference.utils.html" />
    <link rel="prev" title="bayes_dip.inference.exact_predictive_posterior module" href="bayes_dip.inference.exact_predictive_posterior.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Bayes-DIP
          </a>
              <div class="version">
                0.0.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="bayes_dip.html">bayes_dip package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="bayes_dip.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="bayes_dip.data.html">bayes_dip.data package</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayes_dip.dip.html">bayes_dip.dip package</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="bayes_dip.inference.html">bayes_dip.inference package</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="bayes_dip.inference.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="bayes_dip.inference.html#module-bayes_dip.inference">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="bayes_dip.marginal_likelihood_optim.html">bayes_dip.marginal_likelihood_optim package</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayes_dip.probabilistic_models.html">bayes_dip.probabilistic_models package</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayes_dip.utils.html">bayes_dip.utils package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="bayes_dip.html#module-bayes_dip">Module contents</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Bayes-DIP</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="bayes_dip.html">bayes_dip package</a> &raquo;</li>
          <li><a href="bayes_dip.inference.html">bayes_dip.inference package</a> &raquo;</li>
      <li>bayes_dip.inference.sample_based_predictive_posterior module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/_apidoc/bayes_dip.inference.sample_based_predictive_posterior.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-bayes_dip.inference.sample_based_predictive_posterior">
<span id="bayes-dip-inference-sample-based-predictive-posterior-module"></span><h1>bayes_dip.inference.sample_based_predictive_posterior module<a class="headerlink" href="#module-bayes_dip.inference.sample_based_predictive_posterior" title="Permalink to this heading"></a></h1>
<p>Provides a sample based predictive posterior implementation,
<a class="reference internal" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior" title="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">SampleBasedPredictivePosterior</span></code></a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bayes_dip.inference.sample_based_predictive_posterior.</span></span><span class="sig-name descname"><span class="pre">SampleBasedPredictivePosterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_cov</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="bayes_dip.probabilistic_models.base_observation_cov.html#bayes_dip.probabilistic_models.base_observation_cov.BaseObservationCov" title="bayes_dip.probabilistic_models.base_observation_cov.BaseObservationCov"><span class="pre">BaseObservationCov</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bayes_dip/inference/sample_based_predictive_posterior.html#SampleBasedPredictivePosterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="bayes_dip.inference.base_predictive_posterior.html#bayes_dip.inference.base_predictive_posterior.BasePredictivePosterior" title="bayes_dip.inference.base_predictive_posterior.BasePredictivePosterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">BasePredictivePosterior</span></code></a></p>
<p>Approximate sample-based predictive posterior.</p>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.log_prob" title="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.log_prob"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log_prob</span></code></a>(mean, ground_truth[, ...])</p></td>
<td><p>Return the patch-based approximate log probability.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.log_prob_patches" title="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.log_prob_patches"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log_prob_patches</span></code></a>(mean, ground_truth[, ...])</p></td>
<td><p>Return log probabilities for patches.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.sample_zero_mean" title="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.sample_zero_mean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample_zero_mean</span></code></a>(num_samples[, ...])</p></td>
<td><p>Return samples from the Gaussian given by the predictive posterior covariance and mean zero.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.yield_covariances_patches" title="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.yield_covariances_patches"><code class="xref py py-obj docutils literal notranslate"><span class="pre">yield_covariances_patches</span></code></a>([samples, ...])</p></td>
<td><p>Yield posterior covariance matrices for image patches.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_x_correction_term</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.10)"><span class="pre">Dict</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unscaled</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float64</span></span></span><a class="reference internal" href="../_modules/bayes_dip/inference/sample_based_predictive_posterior.html#SampleBasedPredictivePosterior.log_prob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.log_prob" title="Permalink to this definition"></a></dt>
<dd><p>Return the patch-based approximate log probability.</p>
<p>By default, a patch size of <code class="docutils literal notranslate"><span class="pre">1</span></code> pixel, i.e. just the pixel-wise variance is used,
neglecting correlations between different pixels.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>mean</strong><span class="classifier">Tensor</span></dt><dd><p>Mean of the posterior image distribution.</p>
</dd>
<dt><strong>ground_truth</strong><span class="classifier">Tensor</span></dt><dd><p>Ground truth.</p>
</dd>
<dt><strong>noise_x_correction_term</strong><span class="classifier">float or None, optional</span></dt><dd><p>Noise amount that is assumed to be present in ground truth. Can help to stabilize
computations. The default is <code class="docutils literal notranslate"><span class="pre">1e-6</span></code>.</p>
</dd>
<dt><strong>patch_kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Keyword arguments specifying how to split the image into patches.</p>
<dl class="simple">
<dt>The arguments are:</dt><dd><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">'patch_size'</span></code><span class="classifier">int, optional</span></dt><dd><p>The default is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'patch_idx_list'</span></code><span class="classifier">list of int, optional</span></dt><dd><p>Patch indices. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, all patches are used.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'batch_size'</span></code><span class="classifier">int, optional</span></dt><dd><p>The default is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt><strong>unscaled</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the sum of the (unscaled) patch log probabilities is divided by the total
number of pixels in the patches.
Otherwise, the sum of the unscaled patch log probabilities is returned.
The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt><strong>kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Keyword arguments forwarded to <a class="reference internal" href="#bayes_dip.inference.sample_based_predictive_posterior.log_prob_patches" title="bayes_dip.inference.sample_based_predictive_posterior.log_prob_patches"><code class="xref py py-meth docutils literal notranslate"><span class="pre">log_prob_patches()</span></code></a>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>log_probability</strong><span class="classifier">np.float64</span></dt><dd><p>Log probability, optionally scaled; see the <code class="docutils literal notranslate"><span class="pre">unscaled</span></code> argument.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.log_prob_patches">
<span class="sig-name descname"><span class="pre">log_prob_patches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.10)"><span class="pre">Dict</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reweight_off_diagonal_entries</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_x_correction_term</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unscaled</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_patch_diags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.10)"><span class="pre">Dict</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.10)"><span class="pre">Union</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.10)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.10)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.10)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.10)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/bayes_dip/inference/sample_based_predictive_posterior.html#SampleBasedPredictivePosterior.log_prob_patches"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.log_prob_patches" title="Permalink to this definition"></a></dt>
<dd><p>Return log probabilities for patches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>mean</strong><span class="classifier">Tensor</span></dt><dd><p>Mean of the posterior image distribution.</p>
</dd>
<dt><strong>ground_truth</strong><span class="classifier">Tensor</span></dt><dd><p>Ground truth.</p>
</dd>
<dt><strong>samples</strong><span class="classifier">Tensor, optional</span></dt><dd><p>Precomputed samples with mean zero, e.g. drawn by <a class="reference internal" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.sample_zero_mean" title="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.sample_zero_mean"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sample_zero_mean()</span></code></a>.
If not specified, <code class="docutils literal notranslate"><span class="pre">samples_kwargs['num_samples']</span></code> samples are drawn in this function.</p>
</dd>
<dt><strong>patch_kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Keyword arguments specifying the patches, see docs of <a class="reference internal" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.log_prob" title="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.log_prob"><code class="xref py py-meth docutils literal notranslate"><span class="pre">log_prob()</span></code></a>.</p>
</dd>
<dt><strong>reweight_off_diagonal_entries</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, replace the covariance matrix <code class="docutils literal notranslate"><span class="pre">cov</span></code> (for each patch) with
<code class="docutils literal notranslate"><span class="pre">0.5</span> <span class="pre">*</span> <span class="pre">(cov</span> <span class="pre">+</span> <span class="pre">torch.diag(torch.diag(cov)))</span></code>.
The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt><strong>noise_x_correction_term</strong><span class="classifier">float or None, optional</span></dt><dd><p>Noise amount that is assumed to be present in ground truth. Can help to stabilize
computations. The default is <code class="docutils literal notranslate"><span class="pre">1e-6</span></code>.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to print information. The default is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt><strong>unscaled</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the unscaled patch log probabilities are divided by the number of pixels
in the respective patch. Otherwise the unscaled patch log probabilities are returned.
The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt><strong>return_patch_diags</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, return the diagonals of the covariance matrices.
The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt><strong>sample_kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Keyword arguments passed to <a class="reference internal" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.sample_zero_mean" title="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.sample_zero_mean"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sample_zero_mean()</span></code></a>. Required if <code class="docutils literal notranslate"><span class="pre">samples</span> <span class="pre">is</span> <span class="pre">None</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>log_probabilities</strong><span class="classifier">list of float</span></dt><dd><p>Log probabilities for the patches, optionally scaled; see the <code class="docutils literal notranslate"><span class="pre">unscaled</span></code> argument.</p>
</dd>
<dt><strong>patch_diags</strong><span class="classifier">list of Tensor, optional</span></dt><dd><p>Diagonals of the covariance matrices for the patches.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.sample_zero_mean">
<span class="sig-name descname"><span class="pre">sample_zero_mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">cov_obs_mat_chol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_conj_grad_inv</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cg_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.10)"><span class="pre">Dict</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_residual_norm_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_on_device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/bayes_dip/inference/sample_based_predictive_posterior.html#SampleBasedPredictivePosterior.sample_zero_mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.sample_zero_mean" title="Permalink to this definition"></a></dt>
<dd><p>Return samples from the Gaussian given by the predictive posterior covariance and mean zero.</p>
<p>Note that, in contrast to the (abstract) <code class="xref py py-meth docutils literal notranslate"><span class="pre">sample()</span></code> method designated by
<code class="xref py py-class docutils literal notranslate"><span class="pre">BasePredictivePosterior</span></code>, this function does not include an image noise correction
term (and always has mean zero as indicated by the name).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>num_samples</strong><span class="classifier">int</span></dt><dd><p>Number of samples.</p>
</dd>
<dt><strong>cov_obs_mat_chol</strong><span class="classifier">Tensor, optional</span></dt><dd><p>Cholesky factor of the observation covariance matrix.
Required if <code class="docutils literal notranslate"><span class="pre">not</span> <span class="pre">use_conj_grad_inv</span></code>.</p>
</dd>
<dt><strong>batch_size</strong><span class="classifier">int, optional</span></dt><dd><p>Batch size (number of images per batch). The default is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
</dd>
<dt><strong>use_conj_grad_inv</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to use CG instead of <code class="docutils literal notranslate"><span class="pre">cov_obs_mat_chol</span></code> for solving the linear system with the
observation covariance matrix. The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt><strong>cg_kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Keyword arguments passed to <code class="xref py py-func docutils literal notranslate"><span class="pre">bayes_dip.utils.cg()</span></code>.</p>
</dd>
<dt><strong>return_residual_norm_list</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to return the list of residual norms in case of <code class="docutils literal notranslate"><span class="pre">use_conj_grad_inv</span></code>.
The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt><strong>return_on_device</strong><span class="classifier">str or torch.device, optional</span></dt><dd><p>Device on which samples are collected. This option only affects the storage of the
samples to be returned, not their computation.
If <code class="docutils literal notranslate"><span class="pre">None</span></code> (the default), <code class="docutils literal notranslate"><span class="pre">self.observation_cov.device</span></code> is used.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>samples</strong><span class="classifier">Tensor</span></dt><dd><p>Samples from the Gaussian given by the predictive posterior covariance and mean zero.
Shape: <code class="docutils literal notranslate"><span class="pre">(n,</span> <span class="pre">1,</span> <span class="pre">*im_shape)</span></code>, where <code class="docutils literal notranslate"><span class="pre">n</span></code> is
<code class="docutils literal notranslate"><span class="pre">ceil(num_samples</span> <span class="pre">/</span> <span class="pre">batch_size)</span> <span class="pre">*</span> <span class="pre">batch_size</span></code>.</p>
</dd>
<dt><strong>residual_norm_list</strong><span class="classifier">list of scalar, optional</span></dt><dd><p>Residual norms of CG solutions, only returned if
<code class="docutils literal notranslate"><span class="pre">use_conj_grad_inv</span> <span class="pre">and</span> <span class="pre">return_residual_norm_list</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.yield_covariances_patches">
<span class="sig-name descname"><span class="pre">yield_covariances_patches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.10)"><span class="pre">Dict</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_x_correction_term</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.10)"><span class="pre">Dict</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/bayes_dip/inference/sample_based_predictive_posterior.html#SampleBasedPredictivePosterior.yield_covariances_patches"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.yield_covariances_patches" title="Permalink to this definition"></a></dt>
<dd><p>Yield posterior covariance matrices for image patches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>samples</strong><span class="classifier">Tensor, optional</span></dt><dd><p>Precomputed samples with mean zero, e.g. drawn by <a class="reference internal" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.sample_zero_mean" title="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.sample_zero_mean"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sample_zero_mean()</span></code></a>.
If not specified, <code class="docutils literal notranslate"><span class="pre">samples_kwargs['num_samples']</span></code> samples are drawn in this function.</p>
</dd>
<dt><strong>patch_kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Keyword arguments specifying the patches, see docs of <a class="reference internal" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.log_prob" title="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.log_prob"><code class="xref py py-meth docutils literal notranslate"><span class="pre">log_prob()</span></code></a>.</p>
</dd>
<dt><strong>noise_x_correction_term</strong><span class="classifier">float or None, optional</span></dt><dd><p>Noise amount that is assumed to be present in ground truth. The default is <code class="docutils literal notranslate"><span class="pre">1e-6</span></code>.</p>
</dd>
<dt><strong>sample_kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Keyword arguments passed to <a class="reference internal" href="#bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.sample_zero_mean" title="bayes_dip.inference.sample_based_predictive_posterior.SampleBasedPredictivePosterior.sample_zero_mean"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sample_zero_mean()</span></code></a>. Required if <code class="docutils literal notranslate"><span class="pre">samples</span> <span class="pre">is</span> <span class="pre">None</span></code>.</p>
</dd>
<dt><strong>device</strong><span class="classifier">str or torch.device, optional</span></dt><dd><p>Device. If <code class="docutils literal notranslate"><span class="pre">None</span></code> (the default), <code class="docutils literal notranslate"><span class="pre">self.observation_cov.device</span></code> is used.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>batch_patch_inds</strong><span class="classifier">list of int</span></dt><dd><p>Indices of the patches (for the currently yielded batch).</p>
</dd>
<dt><strong>batch_predictive_cov_image_patch</strong><span class="classifier">Tensor</span></dt><dd><p>Covariance matrices.
Shape: <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">max(batch_len_mask_inds),</span> <span class="pre">max(batch_len_mask_inds))</span></code>, where
<code class="docutils literal notranslate"><span class="pre">batch_size</span></code> is <code class="docutils literal notranslate"><span class="pre">patch_kwargs['batch_size']</span></code> for all batches except for the
potentially shorter last batch. If a patch has less than <code class="docutils literal notranslate"><span class="pre">max(batch_len_mask_inds)</span></code>
pixels, the covariance matrix is padded with the identity, i.e. ones on the diagonal and
zeros for the other entries.</p>
</dd>
<dt><strong>batch_len_mask_inds</strong><span class="classifier">list of int</span></dt><dd><p>Numbers of pixels in the patches.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bayes_dip.inference.sample_based_predictive_posterior.approx_predictive_cov_image_patch_from_zero_mean_samples_batched">
<span class="sig-prename descclassname"><span class="pre">bayes_dip.inference.sample_based_predictive_posterior.</span></span><span class="sig-name descname"><span class="pre">approx_predictive_cov_image_patch_from_zero_mean_samples_batched</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_x_correction_term</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/bayes_dip/inference/sample_based_predictive_posterior.html#approx_predictive_cov_image_patch_from_zero_mean_samples_batched"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayes_dip.inference.sample_based_predictive_posterior.approx_predictive_cov_image_patch_from_zero_mean_samples_batched" title="Permalink to this definition"></a></dt>
<dd><p>Estimate the (co-)variances of image pixels from zero mean samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>samples</strong><span class="classifier">Tensor</span></dt><dd><p>Image (or patch) samples with mean zero.
Shape: <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">mc_samples,</span> <span class="pre">num_pixels)</span></code>.</p>
</dd>
<dt><strong>noise_x_correction_term</strong><span class="classifier">float, optional</span></dt><dd><p>If specified, this value is added to the diagonal of each covariance matrix.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>cov</strong><span class="classifier">Tensor</span></dt><dd><p>Covariance estimate, shape: <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_pixels,</span> <span class="pre">num_pixels)</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bayes_dip.inference.sample_based_predictive_posterior.log_prob_patches">
<span class="sig-prename descclassname"><span class="pre">bayes_dip.inference.sample_based_predictive_posterior.</span></span><span class="sig-name descname"><span class="pre">log_prob_patches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.10)"><span class="pre">Dict</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reweight_off_diagonal_entries</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_x_correction_term</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unscaled</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_patch_diags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.10)"><span class="pre">Union</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.10)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.10)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.10)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.10)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/bayes_dip/inference/sample_based_predictive_posterior.html#log_prob_patches"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayes_dip.inference.sample_based_predictive_posterior.log_prob_patches" title="Permalink to this definition"></a></dt>
<dd><p>Return log probabilities for patches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>mean</strong><span class="classifier">Tensor</span></dt><dd><p>Mean of the posterior image distribution.</p>
</dd>
<dt><strong>ground_truth</strong><span class="classifier">Tensor</span></dt><dd><p>Ground truth.</p>
</dd>
<dt><strong>samples</strong><span class="classifier">Tensor</span></dt><dd><p>Precomputed samples, e.g. drawn by <code class="xref py py-meth docutils literal notranslate"><span class="pre">sample_zero_mean()</span></code>.</p>
</dd>
<dt><strong>patch_kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Keyword arguments specifying the patches, see docs of <code class="xref py py-meth docutils literal notranslate"><span class="pre">log_prob()</span></code>.</p>
</dd>
<dt><strong>reweight_off_diagonal_entries</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, replace the covariance matrix <code class="docutils literal notranslate"><span class="pre">cov</span></code> (for each patch) with
<code class="docutils literal notranslate"><span class="pre">0.5</span> <span class="pre">*</span> <span class="pre">(cov</span> <span class="pre">+</span> <span class="pre">torch.diag(torch.diag(cov)))</span></code>.
The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt><strong>noise_x_correction_term</strong><span class="classifier">float or None, optional</span></dt><dd><p>Noise amount that is assumed to be present in ground truth. Can help to stabilize
computations. The default is <code class="docutils literal notranslate"><span class="pre">1e-6</span></code>.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to print information. The default is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt><strong>unscaled</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the unscaled patch log probabilities are divided by the number of pixels in
the respective patch. Otherwise the unscaled patch log probabilities are returned.
The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt><strong>return_patch_diags</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, return the diagonals of the covariance matrices.
The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt><strong>device</strong><span class="classifier">str or torch.device, optional</span></dt><dd><p>Device. If <code class="docutils literal notranslate"><span class="pre">None</span></code> (the default), <code class="docutils literal notranslate"><span class="pre">'cuda:0'</span></code> is chosen if available or <code class="docutils literal notranslate"><span class="pre">'cpu'</span></code>
otherwise.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>log_probabilities</strong><span class="classifier">list of float</span></dt><dd><p>Log probabilities for the patches, optionally scaled; see the <code class="docutils literal notranslate"><span class="pre">unscaled</span></code> argument.</p>
</dd>
<dt><strong>patch_diags</strong><span class="classifier">list of Tensor, optional</span></dt><dd><p>Diagonals of the covariance matrices for the patches.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bayes_dip.inference.sample_based_predictive_posterior.predictive_cov_image_patch_log_prob_unscaled_batched">
<span class="sig-prename descclassname"><span class="pre">bayes_dip.inference.sample_based_predictive_posterior.</span></span><span class="sig-name descname"><span class="pre">predictive_cov_image_patch_log_prob_unscaled_batched</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recon_masked</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth_masked</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictive_cov_image_patch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/bayes_dip/inference/sample_based_predictive_posterior.html#predictive_cov_image_patch_log_prob_unscaled_batched"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayes_dip.inference.sample_based_predictive_posterior.predictive_cov_image_patch_log_prob_unscaled_batched" title="Permalink to this definition"></a></dt>
<dd><p>Return the log probabilities for a batch of patches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>recon_masked</strong><span class="classifier">Tensor</span></dt><dd><p>Reconstruction patches. Shape: <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_pixels)</span></code>.</p>
</dd>
<dt><strong>ground_truth_masked</strong><span class="classifier">Tensor</span></dt><dd><p>Ground truth patches. Shape: <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_pixels)</span></code>.</p>
</dd>
<dt><strong>predictive_cov_image_patch</strong><span class="classifier">Tensor</span></dt><dd><p>Predictive posterior covariance for the patches.
Shape: <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_pixels,</span> <span class="pre">num_pixels)</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>log_prob_unscaled</strong><span class="classifier">Tensor</span></dt><dd><p>Log probabilities of the patches.
Shape: <code class="docutils literal notranslate"><span class="pre">(batch_size,)</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bayes_dip.inference.sample_based_predictive_posterior.predictive_cov_image_patch_norm">
<span class="sig-prename descclassname"><span class="pre">bayes_dip.inference.sample_based_predictive_posterior.</span></span><span class="sig-name descname"><span class="pre">predictive_cov_image_patch_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">v</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictive_cov_image_patch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/bayes_dip/inference/sample_based_predictive_posterior.html#predictive_cov_image_patch_norm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayes_dip.inference.sample_based_predictive_posterior.predictive_cov_image_patch_norm" title="Permalink to this definition"></a></dt>
<dd><p>Return the norm <code class="docutils literal notranslate"><span class="pre">&lt;</span> <span class="pre">cov^(-1)</span> <span class="pre">v</span> <span class="pre">,</span> <span class="pre">v</span> <span class="pre">&gt;</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>v</strong><span class="classifier">Tensor</span></dt><dd><p>Vector(s). Shape: <code class="docutils literal notranslate"><span class="pre">(*,</span> <span class="pre">num_pixels)</span></code>.</p>
</dd>
<dt><strong>predictive_cov_image_patch</strong><span class="classifier">Tensor</span></dt><dd><p>Covariance matrix/matrices. Shape: <code class="docutils literal notranslate"><span class="pre">(*,</span> <span class="pre">num_pixels,</span> <span class="pre">num_pixels)</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>norm</strong><span class="classifier">Tensor</span></dt><dd><p>Norm. Shape: <code class="docutils literal notranslate"><span class="pre">(*,)</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bayes_dip.inference.sample_based_predictive_posterior.yield_covariances_patches">
<span class="sig-prename descclassname"><span class="pre">bayes_dip.inference.sample_based_predictive_posterior.</span></span><span class="sig-name descname"><span class="pre">yield_covariances_patches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.10)"><span class="pre">Dict</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_x_correction_term</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.14.0a0+git9a170b2 ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/bayes_dip/inference/sample_based_predictive_posterior.html#yield_covariances_patches"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayes_dip.inference.sample_based_predictive_posterior.yield_covariances_patches" title="Permalink to this definition"></a></dt>
<dd><p>Yield posterior covariance matrices for image patches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>samples</strong><span class="classifier">Tensor</span></dt><dd><p>Precomputed samples, e.g. drawn by <code class="xref py py-meth docutils literal notranslate"><span class="pre">sample_zero_mean()</span></code>.</p>
</dd>
<dt><strong>patch_kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Keyword arguments specifying the patches, see docs of <code class="xref py py-meth docutils literal notranslate"><span class="pre">log_prob()</span></code>.</p>
</dd>
<dt><strong>noise_x_correction_term</strong><span class="classifier">float or None, optional</span></dt><dd><p>Noise amount that is assumed to be present in ground truth. The default is <code class="docutils literal notranslate"><span class="pre">1e-6</span></code>.</p>
</dd>
<dt><strong>device</strong><span class="classifier">str or torch.device, optional</span></dt><dd><p>Device. If <code class="docutils literal notranslate"><span class="pre">None</span></code> (the default), <code class="docutils literal notranslate"><span class="pre">samples.device</span></code> is used.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>batch_patch_inds</strong><span class="classifier">list of int</span></dt><dd><p>Indices of the patches (for the currently yielded batch).</p>
</dd>
<dt><strong>batch_predictive_cov_image_patch</strong><span class="classifier">Tensor</span></dt><dd><p>Covariance matrices.
Shape: <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">max(batch_len_mask_inds),</span> <span class="pre">max(batch_len_mask_inds))</span></code>, where
<code class="docutils literal notranslate"><span class="pre">batch_size</span></code> is <code class="docutils literal notranslate"><span class="pre">patch_kwargs['batch_size']</span></code> for all batches except for the
potentially shorter last batch. If a patch has less than <code class="docutils literal notranslate"><span class="pre">max(batch_len_mask_inds)</span></code>
pixels, the covariance matrix is padded with the identity, i.e. ones on the diagonal and
zeros for the other entries.</p>
</dd>
<dt><strong>batch_len_mask_inds</strong><span class="classifier">list of int</span></dt><dd><p>Numbers of pixels in the patches.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="bayes_dip.inference.exact_predictive_posterior.html" class="btn btn-neutral float-left" title="bayes_dip.inference.exact_predictive_posterior module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="bayes_dip.inference.utils.html" class="btn btn-neutral float-right" title="bayes_dip.inference.utils module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Riccardo Barbano, Johannes Leuschner, Javier Antorán.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>